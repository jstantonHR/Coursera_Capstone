{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "# Introduction"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "This is the final Capstone Project for the Coursera IBM Data Science course. To finish the course, I decided to use what I have learned on two topics very important to me: Food and my home of California. I decided to do my research on the following cities: Davis (my hometown), Santa Barbara (where I went to university), and San Francisco (my favorite city to visit). The basis of this project will be to get a better idea of potential suggestions for investors and entrepreneurs looking to make a successful investment in a restaurant. Overall, I will serach to see what type of restaurant would be the best and in which city to pwould make the most sense in searching for potential business property.\n\nThe project will attempt to answer the question of how accurately can someone predcit the amount of 'likes' a restaurant opening in these cities can expect to have based on the type of food/cuisine it will serve and which of the 3 Californian cities it will open in. Based on what I learned throughout the course, I will analyze and model the data using different forms of machine learning by comparing both linear and logistic regressions to see which method will yield more accurate preficitive capabilities after training and testing. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "After doing this analysis, I will name this data frame 'raw_dataset' becuase it is the most indepth and complete form of data. \n\nMy first step will be to retrieve the geogrphical coordinates of the 3 mentioned cities (Davis, Santa Barbara, and San Francisco). I will then go ahead and leverage the Foursquare API to obtain the URLs that give me the raw data in JSON form. These URLs will then need to be scraped for the columns: 'name', 'categories', 'latitude', 'longitude', and 'id' for each of the 3 cities. These columns will help identify where each restuarnt is from when doing research on different restaurants from each city. \n\nI will limit my randge of all restaurants found within a 500km radius from the coordinates that are provided from the geolocator. Foursquare provides many categories that are not useful for the data I am looking for, so I will have to clean the results by removing all the rows that are not restaurants. From there, I will need the 'likes' data to come to a final conclusion on what type of food and where the restaurant should be located for our final decision of the business problem. \n\nThe 'id' column will be used to pull the 'likes' in the Foursquare API and append the information into the data frame. I will then conclude by naming the dataframe 'raw_dataset', just I did in the machine learning part of my project. \n"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.7",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}